{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02- Snomed2Vec - Use Model - Methods & Class. V.01.\n",
    "\n",
    "### A new Approach Snomed-CT with word embedding - Snomed2Vec - Model.\n",
    "### Introducción:\n",
    "**Autor:** Ignacio Martinez Soriano. Data Scientist. Hospital Universitario \"Rafael Mendez\" & Medlab Media Group.\n",
    "\n",
    "**Coautores:** \n",
    "* Juan Luis Castro Peña. Dept Ciencias de la computacion e Inteligencia Artificial. Universidad de Granada.\n",
    "* Jesualdo Fernandez Breis. Dept. Informática y Sistemas. Universidad de Murcia.\n",
    "* Ignacio San Román. Dept. Chief Artificial Intelligence Officer . Medlab Media Group.\n",
    "* Adrian Alonso Barriuso. Research Technical Lead. Medlab Media Group.\n",
    "\n",
    "**Fecha:** 28/01/2019.<br>\n",
    "\n",
    "## 1. Introducción:\n",
    "Creación de un nuevo enfoque **Snomed2Vec**<br>\n",
    "Diseño de una herramienta para obtener los conceptos clínicos dentro del texto libre de cualquier informe médico. Asociándole el código mas aproximado, del concepto Snomed-CT. Utilizando **\"Word Embeddings\"** Devolviendo la lista de conceptos Snomed-CT, que aparecen en una frase y sus relaciones con otras entidadades clínicas.<br>\n",
    "\n",
    "**Generación Modelo final Snomed2Vec:**\n",
    "\n",
    "Hemos generado dos modelos:\n",
    "* Uno basado en un dominio local, (Informes de Alta + Descripciones Términos Snomed-CT)\n",
    "* Otro basado en un dominio general, (Artículos de Wikipedia + Descripciones Términos Snomed-CT)\n",
    "\n",
    "Basándonos en los vectores de ese Modelo, aplicamos los vectores de las palabras para generar el Vector final del  Término de la descripción de Snomed-CT:<br>\n",
    "Utilizamos el Modelo generado con Word2Vec, y lo aplicamos a la descripción de Snomed-CT, generando el siguiente vector asociado a la descripción **[d]**<br>\n",
    "Siendo $ V(w_i) $ el Vector asociado a la palabra $ w_i $, según el modelo Word2Vec $ M $.<br>\n",
    "* $ Descripcion-Snomed-CT(d) = (w_1,w_2,...,w_n),=> V[d] = \\sum_{i=1}^{n}v[w_{i}]=v[w_{1}]+v[w_{2}]+...+v[w_{n}] $\n",
    "\n",
    "El Modelo **Snomed2Vec** final: quedaria así:\n",
    "\n",
    "* Un registro para cada concepto con la siguiente estructura:<br>\n",
    "**| Id-Concept | Jerarquia | Descripcion | [Vector de la Descripción] |**\n",
    "\n",
    "### Métodos implementados:\n",
    "\n",
    "Implementamos una version de **Most_Similar()** para obtener los Conceptos similares de  **Snomed-CT**<br>\n",
    "\n",
    "* **Mas_Similar('frase','clase mas proxima')**\n",
    "*  Entrada: **frase**, **clase mas proxima**, se refiere a si se quiere buscar, los conceptos mas cercanos, según la jerarquía de Snomed-CT.\n",
    "*  Salida: (Lista de conceptos, nombrados en la **frase**, proporcionando los mas cercanos según clase buscada)\n",
    "\n",
    "## 2. Snomed-CT:\n",
    "Utilizamos la Ontología **Snomed-CT**, como Terminología clínica,para identificar los conceptos y codificarlos.<br>\n",
    "\n",
    "### Estructura Lógica:\n",
    "\n",
    "**Conceptos:**<br>\n",
    "Cada concepto representa un significado clínico único, al que se referencia con un identificador numérico único de SNOMED CT.\n",
    "\n",
    "**Descripciones:**<br>\n",
    "A cada concepto se asigna un conjunto de descripciones textuales. Éstas constituyen la forma legible de un concepto. Se utilizan dos tipos de descripciones para representar cada concepto - Descripción completa (FSN, por Fully specified name en inglés) y Sinónimo.\n",
    "\n",
    "**Relaciones:**<br>\n",
    "Una relación representa una asociación entre dos conceptos. Las relaciones se utilizan para definir lógicamente el significado de un concepto de manera que pueda procesarlo un ordenador. Un tercer concepto, denominado el tipo de relación (o atributo), se utiliza para representar el significado de la asociación entre el concepto de origen y el de destino. En SNOMED CT existen diferentes tipos de relaciones.\n",
    "\n",
    "**Jerarquías:**<br>\n",
    "Nivel superior con una breve descripción del contenido representado en su rama de la jerarquía.\n",
    "\n",
    ">**|Hallazgo clínico|** representa el resultado de una observación, una evaluación o un juicio clínico e incluye a los conceptos utilizados para representar **diagnósticos**.<br>\n",
    "**|Procedimiento|** representa actividades que se llevan a cabo durante la atención de la salud.<br>\n",
    "**|Situación con contexto explícito|** representa hallazgos clínicos y procedimientos que aún no han ocurrido, (por ejemplo,|antecedente de infarto de miocardio|).<br>\n",
    "**|Entidad observable|** representa una pregunta o una evaluación de las que se puede obtener una respuesta o un resultado (por ejemplo, |presión arterial sistólica|, |color del iris|, |género|). <br>\n",
    "**|Estructura corporal|** representa estructuras anatómicas normales y anormales.<br>\n",
    "**|Organismo|** representa organismos relevantes para la medicina humana y veterinaria.<br>\n",
    "**|Sustancia|** representa sustancias en general, los constituyentes químicos de los productos farmacéuticos/biológicos, sustancias corporales, sustancias alimenticias y diagnósticas. <br>\n",
    "**|Producto farmacéutico / biológico|** representa los productos farmacológicos (por ejemplo, |amoxicilina 250 mg, cápsula|, |paracetamol + codeína comprimido|). <br>\n",
    "**|Espécimen|** representa entidades que se obtienen (por lo general del paciente) para realizar exámenes o análisis.<br>\n",
    "**|Concepto especial|** representa conceptos que no desempeñan ningún papel en la lógica formal del modelo conceptual de la terminología, pero que pueden ser útiles para casos de uso específicos. <br>\n",
    "**|Objeto físico|** representa objetos físicos naturales y fabricados por el hombre.<br>\n",
    "**|Fuerza física|** representa fuerzas físicas que pueden desempeñar un papel como mecanismos de lesión (por ejemplo |fricción|, |radiación|, |corriente alterna|).<br>\n",
    "**|Evento|** representa acontecimientos, con exclusión de procedimientos e intervenciones, (por ejemplo, |terremoto|). <br>\n",
    "**|Ambiente o localización geográfica|** representa tipos de ambientes, así como lugares con nombres propios, como países, estados y regiones.<br>\n",
    "**|Contexto social|** representa condiciones sociales y circunstancias significativas para la atención de la salud.<br>\n",
    "**|Estadificaciones y escalas|** representa escalas de evaluación y sistemas de estadificación tumoral. <br>\n",
    "**|Calificador|** representa los valores para algunos de los atributos de SNOMED CT, cuando esos valores no son subtipos de otros conceptos de nivel superior (por ejemplo, |izquierdo|, |resultado anormal|, |severo|).<br>\n",
    "**|Elemento de registro|** representa contenido creado para brindar información a otras personas sobre eventos de registro o estado de asuntos (por ejemplo, |registro llevado por el paciente|, entrada de registro|, |sección correspondiente a antecedentes familiares|).<br>\n",
    "**|Componente del modelo de SNOMED CT|** contiene los metadatos que se utilizan para la publicación de SNOMED CT. <br>\n",
    "\n",
    "\n",
    "## 3. Generación de los Modelos de Espacio Vectorial, para palabras:\n",
    "\n",
    "Para generar el modelo vectorial de palabras embebidas utilizamos **Word2Vec**, generado por Mikolov et al.<br>\n",
    ">Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013a. [Efficient estimation of word representations in vector space.](https://arxiv.org/abs/1301.3781) In Proceedings of ICLR Workshop\n",
    "\n",
    "\n",
    "**Word2Vec**, es un framework semántico que utiliza una red neuronal superficial de una sola capa oculta, para aprender la representación de la palabra según su contexto.<br>\n",
    "La idea principal es identificar el significado de las palabras, por su  contexto. Esta idea fue desarrollada por Mikolov et al. generando una representacion distribuida de palabras en un espacio vectorial. Permitiendo la agrupación de palabras similares.\n",
    "Para generar los Modelos del espacio vectorial de palabras, utilizamos la libreria Python **gensim:**<br>\n",
    ">[*REHUREK, R., AND SOJKA, P. Software framework for topic modelling with large corpora. New Challenges For NLP Frameworks Programme (May 2010), 45–50.*](https://github.com/RaRe-Technologies/gensim)\n",
    "\n",
    "Los parámetros utilizados para entrenar la red neuronal, han sido:\n",
    "* El modelo elegido ha sido Skip-Gram.\n",
    "* Tamaño del vector. size=300.\n",
    "* Tamaño del a ventana de contexto. Window=8\n",
    "* Mínimas palabras de estudio. min_count=1\n",
    "\n",
    "**Se ha generado los siguientes Modelos:**\n",
    "\n",
    "1. Modelo Dominio local, ampliado con las descripciones de Snomed-CT:<br>\n",
    "Se genera un modelo de espacio vectorial, con **Word2Vec**, basado en los Informes de Alta de urgencias y se añade las descripciones de los términos de Snomed-Ct, para entrenar el modelo.\n",
    "***(SkipGram, vector size=300, windows= 8, Negative=0, min=1)***\n",
    "\n",
    "1. Modelo Dominio general, Wikipedia, ampliado con descripciones Snomed-CT:<br>\n",
    "Se genera un modelo de espacio vectorial, con **Word2Vec**, basado en los datos de la wikipedia en español, ampliada con las descripciones de Snomed-CT.\n",
    "***(SkipGram, vector size=300, windows= 8, Negative=0, min=1)***\n",
    "\n",
    "**Modelo Final:**\n",
    "![Snomed2Vec-Model02](./imagesNB/Snomed2Vec-Model02.png \"Modelo Snomed2Vec\")\n",
    "\n",
    "## 4. Generación Vector para las frases:\n",
    "\n",
    "Una vez generado el modelo elegido, se aplica a las descripciones de Snomed-CT, utilizando un DataSet construido específicamente para este framework. Generando el nuevo modelo **Snomed2Vec**.\n",
    "\n",
    "El DataSet construido está compuesto por los siguientes campos **(id-Concepto, Jerarquia, descripción Concepto)**\n",
    "Para identificar que tipo de concepto estamos seleccionando, se ha utilizado la jerarquia superior del concepto de Snomed-CT, al que pertenece.\n",
    "\n",
    "**Generación Modelo final:**<br>\n",
    "Utillizando los modelos anteriores, se aplica a la descripción del concepto, para generar el vector de la descripción:\n",
    "\n",
    "Siendo $ V(w_i) $ el Vector asociado a la palabra $ w_i $, según el modelo Word2Vec $ M $.<br>\n",
    "* $ Descripcion-Snomed-CT(d) = (w_1,w_2,...,w_n),=> V[d] = \\sum_{i=1}^{n}v[w_{i}]=v[w_{1}]+v[w_{2}]+...+v[w_{n}] $\n",
    "\n",
    "Obteniendo un modelo final **Snomed2Vec**, compuesto por:\n",
    "**(id-Concept | Jerarquia | Descripción | vecSnom(d) )**:\n",
    "![Estructura Snomed2Vec](./imagesNB/SnomedWork.png \"Modelo Snomed2Vec\")\n",
    "\n",
    "\n",
    "## 5. Métodos,  cálculo similaridad y mas_similar():<br>\n",
    "Para calcular los conceptos similares, se aplica la distancia del coseno, entre los vectores de cada palabra o frase:<br>\n",
    "![Distancia Coseno Similaridad](./imagesNB/cosine-similarity.png \"Modelo Snomed2Vec\")\n",
    "\n",
    "### * Snomed2Vec.mas_similar(texto,clase,num_conceptos):*<br>\n",
    "**Entrada:**<br>\n",
    "*texto*=frase secuencia palabras<br>\n",
    "*clase*= Tipo de concepto, para sacar los más proximos, respecto a la entrad de texto.<br>\n",
    "**Sallida:** grado de similaridad = distancia del coseno, entre los vectores de V[texto] y v[Todas Desc Snomed-CT]\n",
    "\n",
    "### * snomed2vec_load (type = 0,1):*\n",
    "Carga del Modelo de espacio vectorial inicial:\n",
    "\n",
    "1. Modelo type = 0 , generado por (Informes de ALta + Descripciones Términos Snomed-CT) Modelo dominio local.\n",
    "1. Modelo type = 1 , generado por (Articulos Wikipedia Español + Descripciones Términos Snomed-CT) Modelo dominio Global.\n",
    "\n",
    "## 6. Resultados de la investigación:\n",
    "* DataSet de Snomed-CT, compuesto por los conceptos con su jerarquia superior, y sus sinónimos.\n",
    "* Modelo Wikipedia en Español, entrenado con word2vec y normalizado. (palabras en minúsculas). Tamañao 300 y con Skip-Gram.\n",
    "* Modelos Snomed2Vec, entrenados, según lso modelos de espacios vectorial, elegidos.\n",
    "* framework, para obtner los conceptos y relaciones, según una frase de entrada. (Por ejemplo un diagnóstico principal).\n",
    "\n",
    "## 7. Data sources, Space vector Models:\n",
    "** Corpus Gold:**\n",
    "\n",
    "## 8. Evaluación y medidas utilizadas:\n",
    "\n",
    "\n",
    "## Final notes:\n",
    "This documentation is part of my PH.D.Thesis and share to improve this new approach.\n",
    "For any comments or help needed with how to test *Snomed2Vec* tool, you can write to: ignacio.martinez@carm.es\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de librerias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Carga de librerias. Versiones en Portatil\n",
    "# numpy 1.13.3\n",
    "# pandas 0.20.3\n",
    "# gensim 2.30\n",
    "import sys\n",
    "#p= r'D:\\Doctorado\\codigo'\n",
    "p='/media/nacho/DatosHD/Doctorado/CBMS2019/codigo'\n",
    "sys.path.append(p)\n",
    "\n",
    "#import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import exp, log, dot, zeros, outer, random, dtype, float32 as REAL,\\\n",
    "    double, uint32, seterr, array, uint8, vstack, fromstring, sqrt, newaxis,\\\n",
    "    ndarray, empty, sum as np_sum, prod, ones, ascontiguousarray, vstack\n",
    "\n",
    "from six import iteritems, itervalues, string_types\n",
    "from six.moves import xrange\n",
    "from gensim import utils, matutils\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import logging\n",
    "import IPython.display as disp\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "pd.set_option('max_colwidth', 100) #para que se impriman las columnas con mayor anchura en el notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Función Snomed2vec_Model, seleccion del Modelo inicial:\n",
    "**Snomed2Vec.load(typeModel)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Modelo de Espacio de vectores aplicado a las descripciones de Snomed:\n",
    "\n",
    "Dependiendo del Modelo elegido, se utilizará,para generer los vectores de cada descripción de Snomed.\n",
    "\n",
    "El vector generado para la descripción **[d]** está formado  por:\n",
    "* $ Descripcion (d) = (w_1,w_2,...,w_n), V[d] = \\sum_{i=1}^{n}v[w_{i}]=v[w_{1}]+v[w_{2}]+...+v[w_{n}] $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Carga Datos DataFrame de Snomed-CT. Snomed2Vec.load(typeModel).\n",
    "Carga del Modelo Snomed2Vec, Entrenado según el modelo elegido.\n",
    "\n",
    "Obtenemos el modelo final:<br>\n",
    "** Carga de Datos Snomed IdConcepto, Jerarquias, TokenTerm, Vector(Segun Modelo):**<br>\n",
    "Modelo generado en el Notebook 20-02.Snomed-CT<br>\n",
    "** Cargar el modelo previamente generado en formato numpy.**<br>\n",
    "fichero *Snomed2Vec-SK300-IA-Op2.npy*<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carga del Modelo elegido, según de la funcion snomed2vec.load.\n",
    "# Utilzia el modelo entrenado Word2Vec, (Word vectors)y el modelo generado final Snomed2Vec.(Sentence vectors)\n",
    "\n",
    "def snomed2vec_load(typeModel=0):\n",
    "    \"\"\" \n",
    "    Dependiendo del parámetro typeModel, se carga los siguientes modelos preentrenados (Word2Vec):\n",
    "    1. typeModel=0 -> Modelo entrenado con los (Informes de ALta de urgencia + Descripcion Snomed-CT)\n",
    "    2. typeModel=1 -> Modelo entrenado con wikipedia en español + Descripción Terminos Snomed-CT.\n",
    "\n",
    "    \"\"\"\n",
    "    if typeModel==0: #Modelo Informes de Alta + Descripciones Snomed-CT\n",
    "        print('Modelo entrenado con los Informes de Alta de Urgencias + Descripciones de Snomed-CT')\n",
    "        fich = '/Models/SKs300w8m1-InfAltSnomed.txt'\n",
    "        fSnomed = '/Models/Snomed2Vec-SK300-IA-Snomed.npy'\n",
    "        \n",
    "    elif typeModel==1: #Modelo Wikipedia\n",
    "        print('Modelo entrenado con la Wikipedia en Español')\n",
    "        fich = '/Models/SKs300w5m1-wikipedia.txt'\n",
    "        fSnomed = '/Models/Snomed2Vec-CBoW300-Wiki-Op3.npy'\n",
    "    \n",
    "    f = p+fich\n",
    "    fSno = p+fSnomed\n",
    "    cols=['idConcept','jerarquia','corpusTerm','vecSnom']\n",
    "    print('Carga del Modelo Snomed2Vec tipo:(%s)' % str(typeModel))\n",
    "    with open(fSno,'rb') as np_file:\n",
    "        data = np.load(np_file)\n",
    "    \n",
    "    return KeyedVectors.load_word2vec_format(f, binary=False), pd.DataFrame(data, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carga del Modelo (dominio local InfAltas+Snomed) typeModel=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado con los Informes de Alta de Urgencias + Descripciones de Snomed-CT\n",
      "Carga del Modelo Snomed2Vec tipo:(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-31 17:56:52,288 : INFO : loading projection weights from /media/nacho/DatosHD/Doctorado/CBMS2019/codigo/Models/SKs300w8m1-InfAltSnomed.txt\n",
      "2019-01-31 17:58:19,546 : INFO : loaded (538631, 300) matrix from /media/nacho/DatosHD/Doctorado/CBMS2019/codigo/Models/SKs300w8m1-InfAltSnomed.txt\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de Carga del modelo type=0\n",
    "w2vModel, SnomedWork = snomed2vec_load(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobación del Modelo Snomed2Vec. Cargado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idConcept</th>\n",
       "      <th>jerarquia</th>\n",
       "      <th>corpusTerm</th>\n",
       "      <th>vecSnom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102002</td>\n",
       "      <td>Sustancia</td>\n",
       "      <td>[hemoglobina, okaloosa]</td>\n",
       "      <td>[0.503108, 0.466876, -0.0276602, -0.234006, -0.116602, 0.484161, 0.125, -0.351791, 0.168337, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102002</td>\n",
       "      <td>Sustancia</td>\n",
       "      <td>[hb, 48, cd7, leu, arg]</td>\n",
       "      <td>[-0.301794, -0.120972, 0.0392014, 0.748237, 0.531802, -0.969592, 0.567389, -1.43454, 0.598673, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103007</td>\n",
       "      <td>Organismo</td>\n",
       "      <td>[virus, fibroma, ardillas]</td>\n",
       "      <td>[1.08219, -0.860717, 0.460997, 0.467138, -0.109274, 0.35905, 0.0495269, -1.52099, 0.485955, -0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104001</td>\n",
       "      <td>Procedimiento</td>\n",
       "      <td>[escision, lesion, rotula]</td>\n",
       "      <td>[0.956222, 0.32638, 0.567415, 0.278348, -0.473122, 1.32149, 0.381964, -0.338385, -0.179837, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104001</td>\n",
       "      <td>Procedimiento</td>\n",
       "      <td>[escision, local, lesion, o, tejido, rotula]</td>\n",
       "      <td>[1.09046, 1.19666, 0.137113, 1.16608, -1.54469, 1.88294, 0.745489, -1.53078, 0.679535, -0.650022...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idConcept      jerarquia                                    corpusTerm  \\\n",
       "0    102002      Sustancia                       [hemoglobina, okaloosa]   \n",
       "1    102002      Sustancia                       [hb, 48, cd7, leu, arg]   \n",
       "2    103007      Organismo                    [virus, fibroma, ardillas]   \n",
       "3    104001  Procedimiento                    [escision, lesion, rotula]   \n",
       "4    104001  Procedimiento  [escision, local, lesion, o, tejido, rotula]   \n",
       "\n",
       "                                                                                               vecSnom  \n",
       "0  [0.503108, 0.466876, -0.0276602, -0.234006, -0.116602, 0.484161, 0.125, -0.351791, 0.168337, -0....  \n",
       "1  [-0.301794, -0.120972, 0.0392014, 0.748237, 0.531802, -0.969592, 0.567389, -1.43454, 0.598673, -...  \n",
       "2  [1.08219, -0.860717, 0.460997, 0.467138, -0.109274, 0.35905, 0.0495269, -1.52099, 0.485955, -0.6...  \n",
       "3  [0.956222, 0.32638, 0.567415, 0.278348, -0.473122, 1.32149, 0.381964, -0.338385, -0.179837, -0.3...  \n",
       "4  [1.09046, 1.19666, 0.137113, 1.16608, -1.54469, 1.88294, 0.745489, -1.53078, 0.679535, -0.650022...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobacion del dataframe:\n",
    "\n",
    "SnomedWork.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comprobación del Modelo\n",
    "#w2vModel.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Proceso temporal para añadirle el concepto con su jerarquia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creación de una columan nueva con el idConcepto+Terminos+Jerarquia\n",
    "def unir3(row):\n",
    "    id = str(row.idConcept)\n",
    "    strTerm = ' '.join(row.corpusTerm)\n",
    "    jer = str(row.jerarquia)\n",
    "    buff = row.idConcept + '|' + strTerm +'|'+row.jerarquia\n",
    "    return buff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SnomedWork['concept'] = SnomedWork[['idConcept','jerarquia','corpusTerm']].apply(unir3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idConcept</th>\n",
       "      <th>jerarquia</th>\n",
       "      <th>corpusTerm</th>\n",
       "      <th>vecSnom</th>\n",
       "      <th>concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102002</td>\n",
       "      <td>Sustancia</td>\n",
       "      <td>[hemoglobina, okaloosa]</td>\n",
       "      <td>[0.503108, 0.466876, -0.0276602, -0.234006, -0.116602, 0.484161, 0.125, -0.351791, 0.168337, -0....</td>\n",
       "      <td>102002|hemoglobina okaloosa|Sustancia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102002</td>\n",
       "      <td>Sustancia</td>\n",
       "      <td>[hb, 48, cd7, leu, arg]</td>\n",
       "      <td>[-0.301794, -0.120972, 0.0392014, 0.748237, 0.531802, -0.969592, 0.567389, -1.43454, 0.598673, -...</td>\n",
       "      <td>102002|hb 48 cd7 leu arg|Sustancia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103007</td>\n",
       "      <td>Organismo</td>\n",
       "      <td>[virus, fibroma, ardillas]</td>\n",
       "      <td>[1.08219, -0.860717, 0.460997, 0.467138, -0.109274, 0.35905, 0.0495269, -1.52099, 0.485955, -0.6...</td>\n",
       "      <td>103007|virus fibroma ardillas|Organismo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104001</td>\n",
       "      <td>Procedimiento</td>\n",
       "      <td>[escision, lesion, rotula]</td>\n",
       "      <td>[0.956222, 0.32638, 0.567415, 0.278348, -0.473122, 1.32149, 0.381964, -0.338385, -0.179837, -0.3...</td>\n",
       "      <td>104001|escision lesion rotula|Procedimiento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104001</td>\n",
       "      <td>Procedimiento</td>\n",
       "      <td>[escision, local, lesion, o, tejido, rotula]</td>\n",
       "      <td>[1.09046, 1.19666, 0.137113, 1.16608, -1.54469, 1.88294, 0.745489, -1.53078, 0.679535, -0.650022...</td>\n",
       "      <td>104001|escision local lesion o tejido rotula|Procedimiento</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idConcept      jerarquia                                    corpusTerm  \\\n",
       "0    102002      Sustancia                       [hemoglobina, okaloosa]   \n",
       "1    102002      Sustancia                       [hb, 48, cd7, leu, arg]   \n",
       "2    103007      Organismo                    [virus, fibroma, ardillas]   \n",
       "3    104001  Procedimiento                    [escision, lesion, rotula]   \n",
       "4    104001  Procedimiento  [escision, local, lesion, o, tejido, rotula]   \n",
       "\n",
       "                                                                                               vecSnom  \\\n",
       "0  [0.503108, 0.466876, -0.0276602, -0.234006, -0.116602, 0.484161, 0.125, -0.351791, 0.168337, -0....   \n",
       "1  [-0.301794, -0.120972, 0.0392014, 0.748237, 0.531802, -0.969592, 0.567389, -1.43454, 0.598673, -...   \n",
       "2  [1.08219, -0.860717, 0.460997, 0.467138, -0.109274, 0.35905, 0.0495269, -1.52099, 0.485955, -0.6...   \n",
       "3  [0.956222, 0.32638, 0.567415, 0.278348, -0.473122, 1.32149, 0.381964, -0.338385, -0.179837, -0.3...   \n",
       "4  [1.09046, 1.19666, 0.137113, 1.16608, -1.54469, 1.88294, 0.745489, -1.53078, 0.679535, -0.650022...   \n",
       "\n",
       "                                                      concept  \n",
       "0                       102002|hemoglobina okaloosa|Sustancia  \n",
       "1                          102002|hb 48 cd7 leu arg|Sustancia  \n",
       "2                     103007|virus fibroma ardillas|Organismo  \n",
       "3                 104001|escision lesion rotula|Procedimiento  \n",
       "4  104001|escision local lesion o tejido rotula|Procedimiento  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SnomedWork.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprobacion de tamaño Modelo Espacio Vectorial (1)- 516211 - 516211\n"
     ]
    }
   ],
   "source": [
    "print('Comprobacion de tamaño Modelo Espacio Vectorial (1)- 516211 - %d' % len(SnomedWork))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Métodos Snomed2Vec.Mas_similar() y Snomed2Vec.Similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Pruebas del método Snomed2vec.Most_similar():\n",
    "Implementacion método Most_Similar para Snomed2Vec. Basado en la implementación de gensim Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Nueva Versión init_Sims para Snomed2Vec:(init_vars)**\n",
    "\n",
    "Se define variables globales, para la generación utilización del espacio vectorial adaptado SNomed2Vec.<br>\n",
    "Matriz tamañp global con el vocabulario. *\"vocab* y con el tamaño del vector, segń el Modelo w2V.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definiciones necesarias:\n",
    "# Definir las siguientes varibles globales.\n",
    "# Matriz formada por el tamaño global del vocabulario \"vocab\" y el tamaño \"size\" del vector de la palabra\n",
    "\n",
    "#Entrada: Se le pasa el dataframe SnomedWork\n",
    "\n",
    "\n",
    "def init_vars(data):\n",
    "    vector_size = len(data['vecSnom'][0])\n",
    "    vocab_size = len(data['vecSnom'])\n",
    "    print(vector_size)\n",
    "    print(vocab_size)\n",
    "    \n",
    "    logging.info(\"precomputing L2-norms of word weight vectors\")\n",
    "    \n",
    "    index2word = data['concept'].tolist() # map from a word's matrix index (int) to word (string)\n",
    "    \n",
    "    syn0 = np.array(data['vecSnom'].tolist(), dtype=REAL)\n",
    "    syn0[np.isnan(syn0)] = 0.0\n",
    "    \n",
    "    syn0norm = zeros((vocab_size, vector_size), dtype=REAL)\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    syn0norm = (syn0 / sqrt((syn0 ** 2).sum(-1))[..., newaxis]).astype(REAL)\n",
    "    \n",
    "    \n",
    "    return syn0, index2word, syn0norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inicialización matrices:**\n",
    "\n",
    "* **syn0**.<br>\n",
    "* **index2word**.<br>\n",
    "* **syn0norm**.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-31 18:05:54,670 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "516211\n"
     ]
    }
   ],
   "source": [
    "syn0, index2word, syn0norm = init_vars(SnomedWork)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Crear Vector para cada token de la frase.\n",
    "Generación de los vectores de los tokens de cada frase.<br>\n",
    "* Funcion **vectorSnomed(frase, Model, size)**, genera un vector por cada token de la frase.\n",
    "    * Entrada: lista de tokens de la **frase**, **model**, **size**, tamaño del vector generado según modelo W2V (300 o 100)\n",
    "    * Salida: lista con los vectores de cada token, de la frase. $$(V[p]=v[tk_{1}]+v[tk_{2}]+...+v[tk_{n}])$$<br>\n",
    "\n",
    "* Funcion: **mas_similar(positive=[], model=w2vModel, topn=10)**\n",
    "    * Entrada: **listGramas**, lista de n-gramas generados, **model**, tamaño del vector, según modelo W2V. **topn**, número máximo de palabras devueltas.(mas similares)\n",
    "    * Salida: lista de palabras devueltas, mas similares, con su distancia. (distancia coseno)\n",
    "\n",
    "* Funcion ****** para crear el vector formado, por la suma de los vectores de las palabras de una frase.<br>\n",
    "La **frase** se pasa como una lista de palabras(lstgrams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorSnomed(lstgrams,model,size):\n",
    "    output=[]\n",
    "    buffer=np.zeros((size,), dtype=np.float32)\n",
    "    for item in lstgrams:\n",
    "        try:\n",
    "            buffer = buffer + model.word_vec(item)\n",
    "        except:\n",
    "            buffer = buffer + np.zeros((size,), dtype=REAL)\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función **mas_similar** , se aplica la distancia del coseno,a la frase pasada como parámetro en el espacio vectorial **Snomed2Vec**  para generar una lista ordenada, de palabras simliras, según su distancia de mas cerca a mas lejos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mas_similar(positive=[], model=w2vModel, topn=10):\n",
    "    \n",
    "    vector=vectorSnomed(positive,model,300)\n",
    "    vectorNorm = (vector / sqrt((vector ** 2).sum(-1))[..., newaxis]).astype(REAL)\n",
    "    \n",
    "    mean = []\n",
    "    mean.append(vectorNorm)\n",
    "    mean = matutils.unitvec(array(mean).mean(axis=0)).astype(REAL)\n",
    "        \n",
    "    limited = syn0norm\n",
    "    dists = dot(limited, mean)\n",
    "    dists[np.isnan(dists)] = 0.0\n",
    "    \n",
    "    best = matutils.argsort(dists, topn=topn, reverse=True)\n",
    "        \n",
    "    result = [(index2word[sim], float(dists[sim])) for sim in best]\n",
    "    return result[:topn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pruebas de ejecucion:\n",
    "* Conjunto de conceptos que se devuelven, dependiendo de sus parámetros.\n",
    "* Pruebas con el modelo type=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función **similares** dependiendo de una frase de entrada, el sistema devuelve:\n",
    "\n",
    "1. Una conjunto de conceptos de Snomed-CT, próximos según la distancia del coseno, aplicada al vector de la frase, en el espacio vectorial.\n",
    "1. las clases de las jerarquias asociadas al concepto de la frase, con el número total de valores asociados.\n",
    "\n",
    "Parámetros de enrada:<br>\n",
    "* **term**: lista de terminos de la frase.<br>\n",
    "* **jer**: Se puede pedir que devuelva, todas las clases de las jerarquias de Snomed-CT, de los conceptos relacionados \"**all**\", o solo una sola jerarquía.<br>\n",
    "* **nMax**: Se puede pedir que saque un número determinado de cada clase.<br>\n",
    "\n",
    "El sistema, devuelve por defecto 1000 conceptos relaciondos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funcion, para identifcar a los conceptos mas similares, dependiendo de sus jerarquias:\n",
    "# Entrada: - frase -jerarquia={'all','cualquier eje de Snomed-CT} -numero de conceptos devueltos\n",
    "# Salida: listado de los conceptos Snomed, según jerarquia y numero de devoluciones\n",
    "\n",
    "import collections\n",
    "\n",
    "def similares(term, jer='all', nMax=3):\n",
    "    lst=[]\n",
    "    jerarquia=[]\n",
    "    bufJer=''\n",
    "    buffer=mas_similar(term, topn=1000)\n",
    "    \n",
    "    for indice in range(len(buffer)):\n",
    "        \n",
    "        buffJer = buffer[indice][0].split('|')[-1]\n",
    "        jerarquia.append(buffJer)\n",
    "        totalJer = collections.Counter(jerarquia)\n",
    "        if jer == 'all':\n",
    "            if totalJer[buffJer]<=nMax:\n",
    "                lst.append(buffer[indice])\n",
    "        elif buffJer == jer:\n",
    "            if totalJer[buffJer]<=nMax:\n",
    "                lst.append(buffer[indice])\n",
    "\n",
    "        #print(buffer[i])\n",
    "    return lst, totalJer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['infarto', 'miocardio', 'agudo']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parámetro de Entrada: \"frase para buscar sus conceptos clínicos\"\n",
    "sent = 'infarto miocardio agudo'\n",
    "term=sent.split()\n",
    "term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "term\n",
    "result, coleccion = similares(term, jer='all',nMax=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('57054005|infarto agudo miocardio|Hallazgo clínico', 1.0),\n",
       " ('233838001|infarto agudo miocardio posterior|Hallazgo clínico',\n",
       "  0.9627053737640381),\n",
       " ('52035003|infarto agudo miocardio anteroapical|Hallazgo clínico',\n",
       "  0.9608805775642395),\n",
       " ('71023004|pericarditis infarto agudo miocardio|Hallazgo clínico',\n",
       "  0.9564796090126038),\n",
       " ('62695002|infarto agudo miocardio anteroseptal|Hallazgo clínico',\n",
       "  0.9539060592651367),\n",
       " ('55470003|infarto agudo|Estructura corporal', 0.9350728392601013),\n",
       " ('428752002|infarto miocardio reciente|Situación con contexto explícito',\n",
       "  0.9322499632835388),\n",
       " ('399211009|antecedente infarto miocardio|Situación con contexto explícito',\n",
       "  0.9179897308349609),\n",
       " ('85844000|infarto transparietal|Estructura corporal', 0.8925144672393799),\n",
       " ('31092005|infarto zahn|Estructura corporal', 0.8845931887626648),\n",
       " ('55641003|infarto|Estructura corporal', 0.8793114423751831),\n",
       " ('287292009|reseccion infarto miocardio|Procedimiento', 0.8745330572128296),\n",
       " ('113155009|educacion infarto miocardio|Procedimiento', 0.8723424077033997),\n",
       " ('81037000|infarto lagunar|Estructura corporal', 0.8721707463264465),\n",
       " ('285721000119104|antecedente infarto agudo miocardio elevacion segmento st|Situación con contexto explícito',\n",
       "  0.8460700511932373),\n",
       " ('266897007|antecedente familiar infarto miocardio|Situación con contexto explícito',\n",
       "  0.8402904272079468),\n",
       " ('103011000119106|arteriosclerosis coronaria paciente antecedente infarto miocardio|Situación con contexto explícito',\n",
       "  0.8335877060890198),\n",
       " ('737438001|plan manejo clinico infarto miocardio|Objeto físico',\n",
       "  0.8287302255630493),\n",
       " ('315287002|infusion insulina glucosa diabetes mellitus infarto agudo miocardio|Procedimiento',\n",
       "  0.7624830603599548),\n",
       " ('64432007|estudio imagenes miocardio|Procedimiento', 0.759335458278656),\n",
       " ('119377007|muestra miocardio|Espécimen', 0.7539552450180054),\n",
       " ('315287002|infusion insulina glucosa poe diabetes mellitus infarto agudo miocardio|Procedimiento',\n",
       "  0.7474725246429443),\n",
       " ('251272004|espesor miocardio|Entidad observable', 0.7342451810836792),\n",
       " ('119377007|especimen miocardio|Espécimen', 0.6816318035125732),\n",
       " ('18131002|agudo fulminante|Calificador', 0.6757736206054688),\n",
       " ('246079009|mecanismo infarto|', 0.6750738620758057),\n",
       " ('373933003|inicio agudo|Calificador', 0.6449878215789795),\n",
       " ('255228009|agudo recurrente|Calificador', 0.6301798224449158),\n",
       " ('6577008|resorcion lacunar|Entidad observable', 0.6272842288017273),\n",
       " ('424227008|mergulo antiguo|Organismo', 0.6158110499382019),\n",
       " ('255426005|isquemico|Calificador', 0.6122795343399048),\n",
       " ('272131007|episodio antiguo|Calificador', 0.6090816855430603),\n",
       " ('415398003|coronavirus hpz 2003 sindrome respiratorio agudo severo|Organismo',\n",
       "  0.5933995246887207),\n",
       " ('415398003|coronavirus hpz 2003 sindrome respiratorio agudo grave|Organismo',\n",
       "  0.571295976638794),\n",
       " ('700590008|stent vascular intracraneal recubierto carburo silicio|Elemento de registro',\n",
       "  0.5698199272155762),\n",
       " ('736288002|plan manejo clinico ataque isquemico transitorio|Objeto físico',\n",
       "  0.5634903311729431),\n",
       " ('367324007|inicio subagudo|', 0.5605919361114502),\n",
       " ('428832008|indice dilatacion isquemica transitoria ventriculo izquierdo|Entidad observable',\n",
       "  0.5565868020057678),\n",
       " ('705639000|stent vascular intracraneal|Elemento de registro',\n",
       "  0.5562883019447327),\n",
       " ('128480004|trastorno agudo sistema hemopoyetico|Concepto especial',\n",
       "  0.5555262565612793),\n",
       " ('415371002|coronavirus cuhk l2 sindrome respiratorio agudo severo|Organismo',\n",
       "  0.5543591976165771),\n",
       " ('415435002|coronavirus sin3 11 sindrome respiratorio agudo severo|Organismo',\n",
       "  0.553907573223114),\n",
       " ('128480004|trastorno agudo sistema hematopoyetico|Concepto especial',\n",
       "  0.5526065826416016)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'': 2,\n",
       "         'Calificador': 10,\n",
       "         'Concepto especial': 2,\n",
       "         'Elemento de registro': 2,\n",
       "         'Entidad observable': 3,\n",
       "         'Espécimen': 2,\n",
       "         'Estructura corporal': 178,\n",
       "         'Hallazgo clínico': 685,\n",
       "         'Objeto físico': 2,\n",
       "         'Organismo': 7,\n",
       "         'Procedimiento': 57,\n",
       "         'Situación con contexto explícito': 50})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coleccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result, coleccion = similares(term, jer='Procedimiento',nMax=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('287292009|reseccion infarto miocardio|Procedimiento', 0.8745330572128296),\n",
       " ('113155009|educacion infarto miocardio|Procedimiento', 0.8723424077033997),\n",
       " ('315287002|infusion insulina glucosa diabetes mellitus infarto agudo miocardio|Procedimiento',\n",
       "  0.7624830603599548)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'': 2,\n",
       "         'Calificador': 10,\n",
       "         'Concepto especial': 2,\n",
       "         'Elemento de registro': 2,\n",
       "         'Entidad observable': 3,\n",
       "         'Espécimen': 2,\n",
       "         'Estructura corporal': 178,\n",
       "         'Hallazgo clínico': 685,\n",
       "         'Objeto físico': 2,\n",
       "         'Organismo': 7,\n",
       "         'Procedimiento': 57,\n",
       "         'Situación con contexto explícito': 50})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coleccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.Ejemplo con otras frases y tamaño de la respuesta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "term\n",
    "result, jerarquias = similares(term,'all' ,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('57054005|infarto agudo miocardio|Hallazgo clínico', 1.0),\n",
       " ('233838001|infarto agudo miocardio posterior|Hallazgo clínico',\n",
       "  0.9627053737640381),\n",
       " ('55470003|infarto agudo|Estructura corporal', 0.9350728392601013),\n",
       " ('428752002|infarto miocardio reciente|Situación con contexto explícito',\n",
       "  0.9322499632835388),\n",
       " ('399211009|antecedente infarto miocardio|Situación con contexto explícito',\n",
       "  0.9179897308349609),\n",
       " ('85844000|infarto transparietal|Estructura corporal', 0.8925144672393799),\n",
       " ('287292009|reseccion infarto miocardio|Procedimiento', 0.8745330572128296),\n",
       " ('113155009|educacion infarto miocardio|Procedimiento', 0.8723424077033997),\n",
       " ('737438001|plan manejo clinico infarto miocardio|Objeto físico',\n",
       "  0.8287302255630493),\n",
       " ('119377007|muestra miocardio|Espécimen', 0.7539552450180054),\n",
       " ('251272004|espesor miocardio|Entidad observable', 0.7342451810836792),\n",
       " ('119377007|especimen miocardio|Espécimen', 0.6816318035125732),\n",
       " ('18131002|agudo fulminante|Calificador', 0.6757736206054688),\n",
       " ('246079009|mecanismo infarto|', 0.6750738620758057),\n",
       " ('373933003|inicio agudo|Calificador', 0.6449878215789795),\n",
       " ('6577008|resorcion lacunar|Entidad observable', 0.6272842288017273)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'': 1,\n",
       "         'Calificador': 3,\n",
       "         'Entidad observable': 2,\n",
       "         'Espécimen': 2,\n",
       "         'Estructura corporal': 119,\n",
       "         'Hallazgo clínico': 326,\n",
       "         'Objeto físico': 1,\n",
       "         'Procedimiento': 21,\n",
       "         'Situación con contexto explícito': 25})"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jerarquias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('712831003|cefaleas frecuentes|Hallazgo clínico', 0.8430951833724976),\n",
       " ('122711000119109|cefalea hipnica|Hallazgo clínico', 0.6640338897705078),\n",
       " ('193028008|cefalea migrañosa|Hallazgo clínico', 0.6571071743965149),\n",
       " ('193031009|cefalea histaminica|Hallazgo clínico', 0.6519134044647217),\n",
       " ('13322008|cefalea postconvulsiva|Hallazgo clínico', 0.6478725671768188),\n",
       " ('193031009|cefalea histaminergica|Hallazgo clínico', 0.6473857760429382),\n",
       " ('193031009|cefalea racimos|Hallazgo clínico', 0.6467556953430176),\n",
       " ('398057008|cefalea tensional|Hallazgo clínico', 0.6464000940322876),\n",
       " ('162309007|cefalea fulgurante|Hallazgo clínico', 0.6456525325775146),\n",
       " ('13322008|cefalea posconvulsiva|Hallazgo clínico', 0.6440224647521973)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term=['cefaleas']\n",
    "mas_similar(term, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('103354007|transparietal| Calificador', 1.0),\n",
       " ('233065007|infundibulectomia| Procedimiento', 0.8605860471725464),\n",
       " ('33973002|endoaneurismoplastia| Procedimiento', 0.8257400989532471),\n",
       " ('281587000|pentalogia cantrell| Hallazgo clínico', 0.8249984979629517),\n",
       " ('189005002|aquilotenotomia hauser| Procedimiento', 0.8225661516189575),\n",
       " ('230193008|neurosarcoidosis| Hallazgo clínico', 0.8200259804725647),\n",
       " ('236849003|opracion fenton| Procedimiento', 0.8197166919708252),\n",
       " ('172938001|faringolaringoesofagectomia| Procedimiento', 0.8176194429397583),\n",
       " ('43785003|aneurismorrafia filipuntura| Procedimiento', 0.8161295652389526),\n",
       " ('223661006|bosnia herzegovina| Ambiente o localización geográfica',\n",
       "  0.8153854012489319)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term=['transparietal']\n",
    "mas_similar(term, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('64662007|infarto pulmonar| Hallazgo clínico', 1.0),\n",
       " ('1001000119102|embolia pulmonar infarto pulmonar| Hallazgo clínico',\n",
       "  0.9283730983734131),\n",
       " ('83727005|infarto pulmonar hemorragico| Hallazgo clínico',\n",
       "  0.9240942001342773),\n",
       " ('230692004|infarto precerebral| Hallazgo clínico', 0.8506897687911987),\n",
       " ('85844000|infarto transparietal| Estructura corporal', 0.8385354280471802),\n",
       " ('64662007|infarto pulmon| Hallazgo clínico', 0.8326650857925415),\n",
       " ('20953001|criptococosis pulmonar| Hallazgo clínico', 0.8307676315307617),\n",
       " ('723859005|embolia pulmonar complicacion actual despues infarto agudo miocardio| Hallazgo clínico',\n",
       "  0.8302592039108276),\n",
       " ('81037000|infarto lagunar| Estructura corporal', 0.8243361711502075),\n",
       " ('31092005|infarto zahn| Estructura corporal', 0.8235911726951599)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term=['infarto', 'pulmonar']\n",
    "mas_similar(term, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualización Resultados finales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.  (Tools) Similaridad, utilizados como base para los nuevos métodos: (ANEXOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(self, w1, w2):\n",
    "        \"\"\"\n",
    "        Compute cosine similarity between two words.\n",
    "        Example::\n",
    "          >>> trained_model.similarity('woman', 'man')\n",
    "          0.73723527\n",
    "          >>> trained_model.similarity('woman', 'woman')\n",
    "          1.0\n",
    "        \"\"\"\n",
    "        return dot(matutils.unitvec(self[w1]), matutils.unitvec(self[w2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funcion similitud Distancia del Coseno, Parametros Vectores\n",
    "def vSimilar(wv1,wv2):\n",
    "    return np.nan_to_num((round(float(np.dot(wv1, wv2)/(np.linalg.norm(wv1) * np.linalg.norm(wv2))),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calcula los n-gramas, segun una lista de tokens, valor n\n",
    "def ngrams(listTokens, n):\n",
    "    output = []  \n",
    "    for i in range(len(listTokens)-n+1):\n",
    "        output.append(listTokens[i:i+n])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Crea todos los n-gramas de una frase según (n)\n",
    "#Salida: lista de n-gramas desde 1 hasta n\n",
    "def todosGramas(listTokens,n):\n",
    "    output=[]\n",
    "    buffer=[]\n",
    "    for i in range(n):\n",
    "        i+=1\n",
    "        output.append(ngrams(listTokens, i))\n",
    "    for i in range(n):\n",
    "        buffer+= output[i]\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entrada: Lista de gramas ['1-grama','2-grama',['3-grama','4-grama]]\n",
    "from nltk.util import skipgrams\n",
    "\n",
    "def skipgramas(frase,n,k):\n",
    "    return(skipgrams(sent, n, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Crear Vector para cada token de la frase.\n",
    "Generación de los vectores de los tokens de cada frase.<br>\n",
    "* Funcion **creaVector(frase, size)**, genera un vector por cada token de la frase.\n",
    "    * Entrada: lista de tokens de la **frase** y **size**, tamaño del vector generado según modelo W2V (300 o 100)\n",
    "    * Salida: lista con los vectores de cada token, de la frase\n",
    "\n",
    "* Funcion: **vectorTotal(listGramas, size)**\n",
    "    * Entrada: **listGramas**, lista de n-gramas generados, **size**, tamaño del vector, según modelo W2V.\n",
    "    * Salida: Vectores asociados a cada frase, si es 1-grama -> Salida Vector(token).<br>\n",
    "      Si la frase tiene **n** gramas -> Salida $$(V[p]=v[tk_{1}]+v[tk_{2}]+...+v[tk_{n}])$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Crear los vectores para todos los ngramas generados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entrada: lista de Frase, con ngramas en sublistas\n",
    "# Ejemplo: todosGramas(textP13,3) \n",
    "# Entrada: ['fiebre','gripe','tos']\n",
    "# Salida: [['fiebre'],['gripe'],['tos'],['fiebre', 'gripe'], ['gripe', 'tos'],['fiebre', 'gripe', 'tos']]\n",
    "\n",
    "def vectorTotal(lstgrams,size):\n",
    "    output=[]\n",
    "    for item in lstgrams:\n",
    "        buffer=np.zeros((size,), dtype=np.float32)\n",
    "        for w in item:\n",
    "            try:\n",
    "                buffer = buffer + w2v_InfAltaSK.word_vec(w)\n",
    "            except:\n",
    "                # Si el token no está en el vocabulario del Modelo, se descarta todos los ngramas\n",
    "                buffer = buffer + np.zeros((size,), dtype=np.float32)\n",
    "                #break\n",
    "        output.append((item, buffer))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Función de Similitud. Snomed2Vec.Most_Similar(), distancia levenshtein(): \n",
    "Función de Similitud, cuando se le pasa los vectores generados. Utilizando la Distancia del Coseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funcion similitud Distancia del Coseno, Parametros Vectores\n",
    "def vSimilar(wv1,wv2):\n",
    "    return np.nan_to_num((round(float(np.dot(wv1, wv2)/(np.linalg.norm(wv1) * np.linalg.norm(wv2))),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levenshtein(first, second):\n",
    "    \"\"\"Return the Levenshtein distance between two strings.\n",
    "    Based on:\n",
    "        http://rosettacode.org/wiki/Levenshtein_distance#Python\n",
    "        implementing at: https://github.com/coloratto/TextRank/blob/master/textrank/__init__.py\n",
    "    \"\"\"\n",
    "    if len(first) > len(second):\n",
    "        first, second = second, first\n",
    "    distances = range(len(first) + 1)\n",
    "    for index2, char2 in enumerate(second):\n",
    "        new_distances = [index2 + 1]\n",
    "        for index1, char1 in enumerate(first):\n",
    "            if char1 == char2:\n",
    "                new_distances.append(distances[index1])\n",
    "            else:\n",
    "                new_distances.append(1 + min((distances[index1],\n",
    "                                             distances[index1 + 1],\n",
    "                                             new_distances[-1])))\n",
    "        distances = new_distances\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def masCercana(w):\n",
    "    cerca=[]\n",
    "    try:\n",
    "        cerca=w2v_InfAltaSK.most_similar(w)\n",
    "    except:\n",
    "        cerca=[]\n",
    "    return cerca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cercanos(sent,n):\n",
    "    simConcept=[]\n",
    "    for w in sent:\n",
    "        buffer = masCercana(w)\n",
    "        if len(masCercana(w))>1:\n",
    "            for i in range(n):\n",
    "                simConcept.append(buffer[i][0])\n",
    "    return simConcept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
